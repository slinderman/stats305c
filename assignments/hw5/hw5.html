

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>HW 5: Poisson Matrix Factorization &#8212; Applied Statistics III</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'assignments/hw5/hw5';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="HW 6: Neural Networks and VAEs" href="../hw6/hw6.html" />
    <link rel="prev" title="HW4: Bayesian Mixture Models" href="../hw4/hw4.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    <p class="title logo__title">Applied Statistics III</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    Overview
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Assignments</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../hw0/hw0.html">HW0: PyTorch Primer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hw1/hw1.html">HW1: Bayesian Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hw2/hw2.html">HW2: Gibbs Sampling and Metropolis-Hastings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hw3/hw3.html">HW3: Continuous Latent Variable Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hw4/hw4.html">HW4: Bayesian Mixture Models</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">HW 5: Poisson Matrix Factorization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hw6/hw6.html">HW 6: Neural Networks and VAEs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Notebooks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/01_bayes_normal.html">Bayesian Analysis of the Normal Distribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/02_mvn.html">The Multivariate Normal Distribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/03_hier_gauss.html">Hierarchical Gaussian Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/04_mcmc.html">Markov Chain Monte Carlo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/09_cavi_gmm.html">Coordinate Ascent Variational Inference for GMMs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/09_cavi_nix.html">CAVI in a Simple Gaussian Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/10_cavi_lda.html">Latent Dirichlet Allocation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/11_advi_nix.html">Gradient-based VI in a Simple Gaussian Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/12_nns_vaes.html">Neural Networks and VAEs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../lectures/99_references.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/slinderman/stats305c/blob/spring2023/assignments/hw5/hw5.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/assignments/hw5/hw5.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>HW 5: Poisson Matrix Factorization</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#background">Background</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#latent-variable-formulation">Latent variable formulation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-1-conditional-distributions-math">Problem 1: Conditional distributions [math]</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-1a-derive-the-conditional-for-mathbf-z-n-m">Problem 1a: Derive the conditional for <span class="math notranslate nohighlight">\(\mathbf{z}_{n, m}\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-1b-derive-the-conditional-for-theta-n-k">Problem 1b: Derive the conditional for <span class="math notranslate nohighlight">\(\theta_{n,k}\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-1c-derive-the-conditional-for-eta-m-k">Problem 1c: Derive the conditional for <span class="math notranslate nohighlight">\(\eta_{m, k}\)</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-2-coordinate-ascent-variational-inference-math">Problem 2: Coordinate ascent variational inference [math]</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-2a-derive-the-cavi-update-for-q-mathbf-z-n-m">Problem 2a: Derive the CAVI update for <span class="math notranslate nohighlight">\(q(\mathbf{z}_{n, m})\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-2b-derive-the-cavi-update-for-q-theta-n-k">Problem 2b: Derive the CAVI update for <span class="math notranslate nohighlight">\(q(\theta_{n, k})\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-2c-derive-the-cavi-update-for-q-eta-m-k">Problem 2c: Derive the CAVI update for <span class="math notranslate nohighlight">\(q(\eta_{m, k})\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-2d-find-the-expected-sufficient-statistics">Problem 2d: Find the expected sufficient statistics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-3-implement-coordinate-ascent-variational-inference-code">Problem 3: Implement Coordinate Ascent Variational Inference [code]</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-3a-implement-a-cavi-update-step">Problem 3a: Implement a CAVI update step</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-3b-elbo-calculation-math">Problem 3b: ELBO Calculation [math]</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-3c-implement-the-elbo-code">Problem 3c: Implement the ELBO [code]</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implement-cavi-loop-given">Implement CAVI loop [given]</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#test-your-implementation-on-a-toy-dataset">Test your implementation on a toy dataset</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-4-run-your-code-on-a-downsampled-lastfm-dataset">Problem 4: Run your code on a downsampled LastFM dataset</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#investigate-genres">Investigate “genres”</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-4a">Problem 4a</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-5-reflections">Problem 5: Reflections</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-5a">Problem 5a</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-5b">Problem 5b</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-5c">Problem 5c</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#submission-instructions">Submission Instructions</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="hw-5-poisson-matrix-factorization">
<h1>HW 5: Poisson Matrix Factorization<a class="headerlink" href="#hw-5-poisson-matrix-factorization" title="Permalink to this heading">#</a></h1>
<hr class="docutils" />
<p><strong>Name:</strong></p>
<p><strong>Collaborators:</strong></p>
<hr class="docutils" />
<section id="background">
<h2>Background<a class="headerlink" href="#background" title="Permalink to this heading">#</a></h2>
<p><strong>Poisson matrix factorization</strong> (PMF) is a mixed membership model like LDA, and it has close ties to non-negative factorization of count matrices. Let <span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{N}^{N \times M}\)</span> denote a count matrix with entries <span class="math notranslate nohighlight">\(x_{n,m}\)</span>. We model each entry as a Poisson random variable,</p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
x_{n,m} &amp;\sim \mathrm{Po}\Big(\boldsymbol{\theta}_{n}^\top \boldsymbol{\eta}_{m} \Big)
= \mathrm{Po}\Big(\sum_{k=1}^K \theta_{n,k} \eta_{m,k} \Big),
\end{align*}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{n} \in \mathbb{R}_+^K\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{\eta}_{m} \in \mathbb{R}_+^K\)</span> are <em>non-negative</em> feature vectors for row <span class="math notranslate nohighlight">\(n\)</span> and column <span class="math notranslate nohighlight">\(m\)</span>, respectively.</p>
<p>PMF has been used for recommender systems, aka collaborative filtering. In a recommender system, the rows correspond to users, the columns to items, and the entries <span class="math notranslate nohighlight">\(x_{n,m}\)</span> to how much user <span class="math notranslate nohighlight">\(n\)</span> liked item <span class="math notranslate nohighlight">\(m\)</span> (on a scale of <span class="math notranslate nohighlight">\(0,1,2,\ldots\)</span> stars, for example). The <span class="math notranslate nohighlight">\(K\)</span> feature dimensions capture different aspects of items that users may weight in their ratings.</p>
<p>Note that the Poisson rate must be non-negative. It is sufficient to ensure <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{n}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{\eta}_{m}\)</span> are non-negative. To that end, PMF uses gamma priors,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\theta_{n,k} &amp;\sim \mathrm{Ga}(\alpha_\theta, \beta_\theta) \\
\eta_{m,k} &amp;\sim \mathrm{Ga}(\alpha_\eta, \beta_\eta),
\end{align*}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\alpha_\star\)</span> and <span class="math notranslate nohighlight">\(\beta_\star\)</span> are hyperparameters. When <span class="math notranslate nohighlight">\(\alpha_\star &lt; 1\)</span>, the gamma distribution has a sharp peak at zero and the prior induces sparsity in the feature vectors.</p>
<section id="latent-variable-formulation">
<h3>Latent variable formulation<a class="headerlink" href="#latent-variable-formulation" title="Permalink to this heading">#</a></h3>
<p>PMF can be rewritten in terms of a latent variable model. Note that,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
x_{n,m} \sim \mathrm{Po}\Big(\sum_{k=1}^K \theta_{n,k} \eta_{m,k} \Big)
\iff x_{n,m} &amp;= \sum_{k=1}^K z_{n,m,k} \\
z_{n,m,k} &amp;\sim \mathrm{Po}(\theta_{nk} \eta_{mk}) \quad \text{independently}.
\end{align*}
\end{split}\]</div>
<p>From this perspective, a user’s rating of an item is a sum of ratings along each feature dimension, and each feature rating is an independent Poisson random variable.</p>
<p>The joint distribution is,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
p(\mathbf{X}, \mathbf{Z}, \boldsymbol{\Theta}, \mathbf{H}) 
&amp;= 
\left[\prod_{n=1}^N \prod_{m=1}^M \mathbb{I}\Big[x_{n,m}=\sum_{k=1}^K z_{n,m,k} \Big] 
\prod_{k=1}^K \mathrm{Po}(z_{n,m,k} \mid \theta_{n,k} \eta_{m,k}) 
\right] \\
&amp;\qquad
\times \left[ \prod_{n=1}^N \prod_{k=1}^K \mathrm{Ga}(\theta_{n,k} \mid \alpha_\theta, \beta_\theta) \right]
\times \left[ \prod_{m=1}^M \prod_{k=1}^K \mathrm{Ga}(\eta_{m,k} \mid \alpha_\eta, \beta_\eta) \right]
\end{align*}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{Z} \in \mathbb{N}^{N\times M \times K}\)</span> denotes the <em>tensor</em> of feature ratings, <span class="math notranslate nohighlight">\(\boldsymbol{\Theta} \in \mathbb{R}_+^{N \times K}\)</span> is a matrix with rows <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_n\)</span>, and <span class="math notranslate nohighlight">\(\mathbf{H} \in \mathbb{R}_+^{M \times K}\)</span> is a matrix with rows <span class="math notranslate nohighlight">\(\boldsymbol{\eta}_m\)</span>.</p>
</section>
</section>
<section id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.distributions</span> <span class="kn">import</span> <span class="n">Distribution</span><span class="p">,</span> <span class="n">Gamma</span><span class="p">,</span> <span class="n">Poisson</span><span class="p">,</span> <span class="n">Multinomial</span>
<span class="kn">from</span> <span class="nn">torch.distributions.kl</span> <span class="kn">import</span> <span class="n">kl_divergence</span>

<span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">trange</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s2">&quot;notebook&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="problem-1-conditional-distributions-math">
<h2>Problem 1: Conditional distributions [math]<a class="headerlink" href="#problem-1-conditional-distributions-math" title="Permalink to this heading">#</a></h2>
<p>Since this model is constructed from conjugate exponential family distributions, the conditionals are available in closed form. We will let <span class="math notranslate nohighlight">\(\mathbf{z}_{n,m} = (z_{n,m,1}, \ldots, z_{n,m,K})\)</span>.</p>
<section id="problem-1a-derive-the-conditional-for-mathbf-z-n-m">
<h3>Problem 1a: Derive the conditional for <span class="math notranslate nohighlight">\(\mathbf{z}_{n, m}\)</span><a class="headerlink" href="#problem-1a-derive-the-conditional-for-mathbf-z-n-m" title="Permalink to this heading">#</a></h3>
<p>Find the conditional density <span class="math notranslate nohighlight">\(p(\mathbf{z}_{n,m} \mid x_{n,m}, \boldsymbol{\theta}_{n}, \boldsymbol{\eta}_{m})\)</span>.</p>
<hr class="docutils" />
<p><em>Your answer here.</em></p>
</section>
<hr class="docutils" />
<section id="problem-1b-derive-the-conditional-for-theta-n-k">
<h3>Problem 1b: Derive the conditional for <span class="math notranslate nohighlight">\(\theta_{n,k}\)</span><a class="headerlink" href="#problem-1b-derive-the-conditional-for-theta-n-k" title="Permalink to this heading">#</a></h3>
<p>Find the conditional density <span class="math notranslate nohighlight">\(p(\theta_{n,k} \mid \mathbf{Z}, \mathbf{H})\)</span>.</p>
<hr class="docutils" />
<p><em>Your answer here.</em></p>
</section>
<hr class="docutils" />
<section id="problem-1c-derive-the-conditional-for-eta-m-k">
<h3>Problem 1c: Derive the conditional for <span class="math notranslate nohighlight">\(\eta_{m, k}\)</span><a class="headerlink" href="#problem-1c-derive-the-conditional-for-eta-m-k" title="Permalink to this heading">#</a></h3>
<p>Find the conditional density <span class="math notranslate nohighlight">\(p(\eta_{m, k} \mid \mathbf{Z}, \mathbf{\Theta})\)</span>.</p>
<hr class="docutils" />
<p><em>Your answer here.</em></p>
</section>
</section>
<hr class="docutils" />
<section id="problem-2-coordinate-ascent-variational-inference-math">
<h2>Problem 2: Coordinate ascent variational inference [math]<a class="headerlink" href="#problem-2-coordinate-ascent-variational-inference-math" title="Permalink to this heading">#</a></h2>
<p>We will perform inference in this model using a mean-field variational posterior which factorizes according to:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
q(\mathbf{Z}, \mathbf{H}, \boldsymbol{\Theta}) 
&amp;= q(\mathbf{Z}) q(\mathbf{H}) q(\boldsymbol{\Theta}) \\
&amp;= \left[\prod_{n = 1}^N \prod_{m = 1}^M q(\mathbf{z}_{n, m}) \right] \left[\prod_{n = 1}^N \prod_{k = 1}^K q(\theta_{n, k}) \right] \left[ \prod_{m = 1}^M \prod_{k = 1}^K q(\eta_{m, k}) \right]
\end{align*}
\end{split}\]</div>
<p>The optimal mean field factors will have the same forms as the conditional distributions above.</p>
<section id="problem-2a-derive-the-cavi-update-for-q-mathbf-z-n-m">
<h3>Problem 2a: Derive the CAVI update for <span class="math notranslate nohighlight">\(q(\mathbf{z}_{n, m})\)</span><a class="headerlink" href="#problem-2a-derive-the-cavi-update-for-q-mathbf-z-n-m" title="Permalink to this heading">#</a></h3>
<p>Show that, fixing <span class="math notranslate nohighlight">\(q(\mathbf{H})\)</span> and <span class="math notranslate nohighlight">\(q(\boldsymbol{\Theta})\)</span>, the optimal <span class="math notranslate nohighlight">\(q(\mathbf{z}_{n, m})\)</span> is given by:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
q(\mathbf{z}_{n,m}; \boldsymbol{\lambda}^{(z)}_{n,m}) 
&amp;= \mathrm{Mult}(\mathbf{z}_{n,m}; x_{n,m}, \boldsymbol{\lambda}^{(z)}_{n,m}) \\
\log \lambda^{(z)}_{n,m,k} &amp;= \mathbb{E}_q[\log \theta_{n,k} + \log \eta_{m,k}] + c
\end{align*}
\end{split}\]</div>
<hr class="docutils" />
<p><em>Your answer here.</em></p>
</section>
<hr class="docutils" />
<section id="problem-2b-derive-the-cavi-update-for-q-theta-n-k">
<h3>Problem 2b: Derive the CAVI update for <span class="math notranslate nohighlight">\(q(\theta_{n, k})\)</span><a class="headerlink" href="#problem-2b-derive-the-cavi-update-for-q-theta-n-k" title="Permalink to this heading">#</a></h3>
<p>Show that, fixing <span class="math notranslate nohighlight">\(q(\mathbf{Z})\)</span> and <span class="math notranslate nohighlight">\(q(\mathbf{H})\)</span>, the optimal <span class="math notranslate nohighlight">\(q(\theta_{n, k})\)</span> is given by:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
q(\theta_{n,k}; {\lambda}^{(\theta)}_{n,k,1}, {\lambda}^{(\theta)}_{n,k,2}) 
&amp;= \mathrm{Ga}(\theta_{n,k}; {\lambda}^{(\theta)}_{n,k,1}, {\lambda}^{(\theta)}_{n,k,2}) \\
{\lambda}^{(\theta)}_{n,k,1} &amp;=  \alpha_\theta + \sum_{m=1}^M \mathbb{E}_q[z_{n,m,k}] \\
{\lambda}^{(\theta)}_{n,k,2} &amp;=  \beta_\theta + \sum_{m=1}^M \mathbb{E}_q[\eta_{m,k}] 
\end{align*}
\end{split}\]</div>
<hr class="docutils" />
<p><em>Your answer here.</em></p>
</section>
<hr class="docutils" />
<section id="problem-2c-derive-the-cavi-update-for-q-eta-m-k">
<h3>Problem 2c: Derive the CAVI update for <span class="math notranslate nohighlight">\(q(\eta_{m, k})\)</span><a class="headerlink" href="#problem-2c-derive-the-cavi-update-for-q-eta-m-k" title="Permalink to this heading">#</a></h3>
<p>Show that, fixing <span class="math notranslate nohighlight">\(q(\mathbf{Z})\)</span> and <span class="math notranslate nohighlight">\(q(\boldsymbol{\Theta})\)</span>, the optimal <span class="math notranslate nohighlight">\(q(\eta_{m, k})\)</span> is given by:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
q(\eta_{m,k}; {\lambda}^{(\eta)}_{m,k,1}, {\lambda}^{(\eta)}_{m,k,2}) 
&amp;= \mathrm{Ga}(\eta_{m,k}; {\lambda}^{(\eta)}_{m,k,1}, \lambda^{(\eta)}_{m,k,2}) \\
{\lambda}^{(\eta)}_{m,k,1} &amp;=  \alpha_\eta + \sum_{n=1}^N \mathbb{E}_q[z_{n,m,k}] \\
{\lambda}^{(\eta)}_{m,k,2} &amp;=  \beta_\eta + \sum_{n=1}^N \mathbb{E}_q[\theta_{n,k}] 
\end{align*}
\end{split}\]</div>
<hr class="docutils" />
<p><em>Your answer here.</em></p>
</section>
<hr class="docutils" />
<section id="problem-2d-find-the-expected-sufficient-statistics">
<h3>Problem 2d: Find the expected sufficient statistics<a class="headerlink" href="#problem-2d-find-the-expected-sufficient-statistics" title="Permalink to this heading">#</a></h3>
<p>To update the variational factors, we need the expectations <span class="math notranslate nohighlight">\(\mathbb{E}_q[z_{n, m, k}]\)</span>, <span class="math notranslate nohighlight">\(\mathbb{E}_q[\log \theta_{n,k} + \log \eta_{m,k}]\)</span>, <span class="math notranslate nohighlight">\(\mathbb{E}_q[\theta_{n, k}]\)</span>, and <span class="math notranslate nohighlight">\(\mathbb{E}_q[\eta_{m, k}]\)</span>. Assume that each factor follows the forms derived above. That is, assume <span class="math notranslate nohighlight">\(q(\mathbf{z}_{n, m})\)</span> is multinomial with parameters <span class="math notranslate nohighlight">\(\lambda_{n, m}^{(z)}\)</span> while <span class="math notranslate nohighlight">\(q(\theta_{n, k})\)</span> and <span class="math notranslate nohighlight">\(q(\eta_{m k})\)</span> are gamma with parameters <span class="math notranslate nohighlight">\(\left( \lambda_{n, k, 1}^{(\theta)}, \lambda_{n, k, 2}^{(\theta)} \right)\)</span> and <span class="math notranslate nohighlight">\(\left( \lambda_{m, k, 1}^{(\eta)}, \lambda_{m, k, 2}^{(\eta)} \right)\)</span>, respectively. Derive what each of these expectations are in closed form.</p>
<hr class="docutils" />
<p><em>Your answer here.</em></p>
</section>
</section>
<hr class="docutils" />
<section id="problem-3-implement-coordinate-ascent-variational-inference-code">
<h2>Problem 3: Implement Coordinate Ascent Variational Inference [code]<a class="headerlink" href="#problem-3-implement-coordinate-ascent-variational-inference-code" title="Permalink to this heading">#</a></h2>
<p>First we’ll give some helper functions and objects. Because PyTorch doesn’t offer support for batched multinomial distributions in which the total counts differ (e.g. each <span class="math notranslate nohighlight">\(\mathbf{z}_{n, m}\)</span> follows a multinomial distribution in which the total count is <span class="math notranslate nohighlight">\(x_{n, m}\)</span>), we have defined a <code class="docutils literal notranslate"><span class="pre">BatchedMultinomial</span></code> distribution for your convenience. This distribution doesn’t support sampling, but will return the mean of each Multinomial variable in its batch. This is exactly what is needed for the CAVI updates.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gamma_expected_log</span><span class="p">(</span><span class="n">gamma_distbn</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Helper function to compute the expectation of log(X) where X follows a </span>
<span class="sd">    gamma distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">digamma</span><span class="p">(</span><span class="n">gamma_distbn</span><span class="o">.</span><span class="n">concentration</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">gamma_distbn</span><span class="o">.</span><span class="n">rate</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">BatchedMultinomial</span><span class="p">(</span><span class="n">Multinomial</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; </span>
<span class="sd">    Creates a Multinomial distribution parameterized by `total_count` and</span>
<span class="sd">    either `probs` or `logits` (but not both). The innermost dimension of</span>
<span class="sd">    `probs` indexes over categories. All other dimensions index over batches.</span>

<span class="sd">    The `probs` argument must be non-negative, finite and have a non-zero sum,</span>
<span class="sd">    and it will be normalized to sum to 1 along the last dimension. `probs` will </span>
<span class="sd">    return this normalized value. The `logits` argument will be interpreted as </span>
<span class="sd">    unnormalized log probabilities and can therefore be any real number. It will</span>
<span class="sd">    likewise be normalized so that the resulting probabilities sum to 1 along</span>
<span class="sd">    the last dimension. `logits` will return this normalized value.</span>

<span class="sd">    Args:</span>
<span class="sd">        total_count (Tensor): number of trials</span>
<span class="sd">        probs (Tensor): event probabilities</span>
<span class="sd">            Has shape total_count.shape + (num_categories,)</span>
<span class="sd">        logits (Tensor): event log probabilities (unnormalized)</span>
<span class="sd">            Has shape total_count.shape + (num_categories,)</span>

<span class="sd">    Note: this text is mostly from the PyTorch documentation for the </span>
<span class="sd">        Multinomial distribution</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">total_count</span><span class="p">,</span> <span class="n">probs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">logits</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">validate_args</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">probs</span><span class="o">=</span><span class="n">probs</span><span class="p">,</span> <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">validate_args</span><span class="o">=</span><span class="n">validate_args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_count</span> <span class="o">=</span> <span class="n">total_count</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">mean</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_count</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">probs</span>
</pre></div>
</div>
</div>
</div>
<section id="problem-3a-implement-a-cavi-update-step">
<h3>Problem 3a: Implement a CAVI update step<a class="headerlink" href="#problem-3a-implement-a-cavi-update-step" title="Permalink to this heading">#</a></h3>
<p>Using the update equations derived in Problem 2, complete the <code class="docutils literal notranslate"><span class="pre">cavi_step</span></code> function below.</p>
<p><em>Hint:</em> Given a <code class="docutils literal notranslate"><span class="pre">Distribution</span></code> named <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">d.mean</span></code> returns the mean of that distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">cavi_step</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">q_z</span><span class="p">,</span> <span class="n">q_theta</span><span class="p">,</span> <span class="n">q_eta</span><span class="p">,</span> <span class="n">alpha_theta</span><span class="p">,</span> <span class="n">beta_theta</span><span class="p">,</span> <span class="n">alpha_eta</span><span class="p">,</span> <span class="n">beta_eta</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;One step of CAVI.</span>

<span class="sd">    Args:</span>
<span class="sd">        X: torch.tensor of shape (N, M)</span>
<span class="sd">        q_z: variational posterior over z, BatchedMultinomial distribution</span>
<span class="sd">        q_theta: variational posterior over theta, Gamma distribution</span>
<span class="sd">        q_eta: variational posterior over eta, Gamma distribution</span>

<span class="sd">    Returns:</span>
<span class="sd">        (q_z, q_theta, q_eta): Updated distributions after performing CAVI updates</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1">###</span>
    <span class="c1"># Your code here</span>

    <span class="c1"># Update q_z</span>
    <span class="n">q_z</span> <span class="o">=</span> <span class="n">BatchedMultinomial</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    
    <span class="c1"># Update the per-user posterior q_theta</span>
    <span class="n">q_theta</span> <span class="o">=</span> <span class="n">Gamma</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    
    <span class="c1"># Update the per-item posterior q_eta</span>
    <span class="n">q_eta</span> <span class="o">=</span> <span class="n">Gamma</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    
    <span class="c1">#</span>
    <span class="c1">##</span>

    <span class="k">return</span> <span class="n">q_z</span><span class="p">,</span> <span class="n">q_theta</span><span class="p">,</span> <span class="n">q_eta</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="problem-3b-elbo-calculation-math">
<h3>Problem 3b: ELBO Calculation [math]<a class="headerlink" href="#problem-3b-elbo-calculation-math" title="Permalink to this heading">#</a></h3>
<p>Recall that the evidence lower bound is defined as:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(q) = \mathbb{E}_q \left[ \log p(\mathbf{X}, \mathbf{Z}, \mathbf{H}, \boldsymbol{\Theta}) - \log q(\mathbf{Z}, \mathbf{H}, \boldsymbol{\Theta}) \right]
\]</div>
<p>Assume that <span class="math notranslate nohighlight">\(q(\mathbf{Z})\)</span> has support contained in <span class="math notranslate nohighlight">\(\{\mathbf{Z}: \sum_{k=1}^K z_{n, m, k} = x_{n, m} \text{ for all } n, m\}\)</span>. Show that we can rewrite <span class="math notranslate nohighlight">\(\mathcal{L}(q)\)</span> as:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(q) = \mathbb{E}_q [\log p(\mathbf{Z} \mid \boldsymbol{\Theta}, \mathbf{H}) - \log q(\mathbf{Z})]  - \mathrm{KL}(q(\boldsymbol{\Theta}) || p(\boldsymbol{\Theta})) - \mathrm{KL}(q(\mathbf{H}) || p(\mathbf{H}))
\]</div>
<p>Next, use that <span class="math notranslate nohighlight">\(q(\mathbf{z}_{n,m}; \boldsymbol{\lambda}^{(z)}_{n,m}) =  \mathrm{Mult}(\mathbf{z}_{n,m}; x_{n,m}, \boldsymbol{\lambda}^{(z)}_{n,m})\)</span> and by plug in the densities of the Poisson and Multinomial distributions to show that we have:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
&amp;\mathbb{E}_q [\log p(\mathbf{Z} \mid \boldsymbol{\Theta}, \mathbf{H}) - \log q(\mathbf{Z})] 
= \\
&amp;\qquad \sum_{n = 1}^N \sum_{m = 1}^M \mathbb{E}_q \left[ \sum_{k =1}^K - \theta_{n, k} \eta_{m, k}  + z_{n, m, k} \log( \theta_{n, k} \eta_{m, k} ) - z_{n,m, k} \log(\lambda_{n, m, k}^{(z)}) \right] - \log(x_{n, m}!)
\end{align*}
\end{split}\]</div>
<p>Explain why we have:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
&amp;\mathbb{E}_q \left[ - \theta_{n, k} \eta_{m, k}  + z_{n, m, k} \log( \theta_{n, k} \eta_{m, k} ) - z_{n,m, k} \log(\lambda_{n, m, k}^{(z)}) \right] = \\
&amp;\qquad - \mathbb{E}_q \left[\theta_{n, k}\right] \mathbb{E}_q \left[\eta_{m, k}\right]  + \mathbb{E}_q \left[z_{n, m, k} \right] \left( \mathbb{E}_q \left[\log( \theta_{n, k}) \right] + \mathbb{E}_q \left[\log (\eta_{m, k} )\right] - \log(\lambda_{n, m, k}^{(z)}) \right)  
\end{align*}
\end{split}\]</div>
<hr class="docutils" />
<p><em>Your answer here.</em></p>
</section>
<hr class="docutils" />
<section id="problem-3c-implement-the-elbo-code">
<h3>Problem 3c: Implement the ELBO [code]<a class="headerlink" href="#problem-3c-implement-the-elbo-code" title="Permalink to this heading">#</a></h3>
<p>Using our expression above, write a function which evaluates the evidence lower bound.</p>
<p><em>Hints:</em></p>
<ul class="simple">
<li><p>Use the <code class="docutils literal notranslate"><span class="pre">kl_divergence</span></code> function imported above to compute the KL divergence between two <code class="docutils literal notranslate"><span class="pre">Distributions</span></code> in the same family.</p></li>
<li><p>Recall that for integers <span class="math notranslate nohighlight">\(n\)</span>, <span class="math notranslate nohighlight">\(\Gamma(n + 1) = n!\)</span> where <span class="math notranslate nohighlight">\(\Gamma\)</span> is the <a class="reference external" href="https://en.wikipedia.org/wiki/Gamma_function">Gamma function</a>. <span class="math notranslate nohighlight">\(\log \Gamma\)</span> is implemented in PyTorch as <code class="docutils literal notranslate"><span class="pre">torch.lgamma</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">elbo</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">q_z</span><span class="p">,</span> <span class="n">q_theta</span><span class="p">,</span> <span class="n">q_eta</span><span class="p">,</span> <span class="n">p_theta</span><span class="p">,</span> <span class="n">p_eta</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the evidence lower bound.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        X: torch.tensor of shape (N, M)</span>
<span class="sd">        q_z: variational posterior over z, BatchedMultinomial distribution</span>
<span class="sd">        q_theta: variational posterior over theta, Gamma distribution</span>
<span class="sd">        q_eta: variational posterior over eta, Gamma distribution</span>
<span class="sd">        p_theta: prior over theta, Gamma distribution</span>
<span class="sd">        p_eta: prior over eta, Gamma distribution</span>

<span class="sd">    Returns:</span>
<span class="sd">        elbo: torch.tensor of shape [] </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1">###</span>
    <span class="c1"># Your code below</span>
    <span class="n">elbo</span> <span class="o">=</span> <span class="o">...</span>
    <span class="c1">#</span>
    <span class="c1">##</span>
    <span class="k">return</span> <span class="n">elbo</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="implement-cavi-loop-given">
<h3>Implement CAVI loop [given]<a class="headerlink" href="#implement-cavi-loop-given" title="Permalink to this heading">#</a></h3>
<p>Using your functions defined above, complete the function <code class="docutils literal notranslate"><span class="pre">cavi</span></code> below. <code class="docutils literal notranslate"><span class="pre">cavi</span></code> loops for some number of iterations, updating each of the variational factors in sequence and evaluating the ELBO at each step.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.distributions</span> <span class="kn">import</span> <span class="n">Uniform</span>

<span class="k">def</span> <span class="nf">cavi</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> 
         <span class="n">num_factors</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
         <span class="n">num_iters</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> 
         <span class="n">tol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> 
         <span class="n">alpha_theta</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
         <span class="n">beta_theta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
         <span class="n">alpha_eta</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
         <span class="n">beta_eta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
         <span class="n">seed</span><span class="o">=</span><span class="mi">0</span>
        <span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run coordinate ascent VI for Poisson matrix factorization.</span>

<span class="sd">    Args:</span>

<span class="sd">    Returns:</span>
<span class="sd">        elbos, (q_z, q_theta, q_eta):</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="n">N</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">K</span> <span class="o">=</span> <span class="n">num_factors</span>      <span class="c1"># short hand</span>
    
    <span class="c1"># Initialize the variational posteriors.</span>
    <span class="n">q_eta</span> <span class="o">=</span> <span class="n">Gamma</span><span class="p">(</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">alpha_eta</span><span class="p">,</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">alpha_eta</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">K</span><span class="p">)),</span>
                  <span class="n">Uniform</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">beta_eta</span><span class="p">,</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">beta_eta</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">K</span><span class="p">)))</span>
    <span class="n">q_theta</span> <span class="o">=</span> <span class="n">Gamma</span><span class="p">(</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">alpha_theta</span><span class="p">,</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">alpha_theta</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">K</span><span class="p">)),</span>
                    <span class="n">Uniform</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">beta_theta</span><span class="p">,</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">beta_theta</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">K</span><span class="p">)))</span>
    <span class="n">q_z</span> <span class="o">=</span> <span class="n">BatchedMultinomial</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">logits</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">K</span><span class="p">)))</span>

    <span class="n">p_theta</span> <span class="o">=</span> <span class="n">Gamma</span><span class="p">(</span><span class="n">alpha_theta</span><span class="p">,</span> <span class="n">beta_theta</span><span class="p">)</span>
    <span class="n">p_eta</span> <span class="o">=</span> <span class="n">Gamma</span><span class="p">(</span><span class="n">alpha_eta</span><span class="p">,</span> <span class="n">beta_eta</span><span class="p">)</span>
    
    <span class="c1"># Run CAVI</span>
    <span class="n">elbos</span> <span class="o">=</span> <span class="p">[</span><span class="n">elbo</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">q_z</span><span class="p">,</span> <span class="n">q_theta</span><span class="p">,</span> <span class="n">q_eta</span><span class="p">,</span> <span class="n">p_theta</span><span class="p">,</span> <span class="n">p_eta</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">itr</span> <span class="ow">in</span> <span class="n">trange</span><span class="p">(</span><span class="n">num_iters</span><span class="p">):</span>
        <span class="n">q_z</span><span class="p">,</span> <span class="n">q_theta</span><span class="p">,</span> <span class="n">q_eta</span> <span class="o">=</span> <span class="n">cavi_step</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">q_z</span><span class="p">,</span> <span class="n">q_theta</span><span class="p">,</span> <span class="n">q_eta</span><span class="p">,</span>
                                        <span class="n">alpha_theta</span><span class="p">,</span> <span class="n">beta_theta</span><span class="p">,</span>
                                        <span class="n">alpha_eta</span><span class="p">,</span> <span class="n">beta_eta</span><span class="p">)</span>
        
        <span class="n">elbos</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">elbo</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">q_z</span><span class="p">,</span> <span class="n">q_theta</span><span class="p">,</span> <span class="n">q_eta</span><span class="p">,</span> <span class="n">p_theta</span><span class="p">,</span> <span class="n">p_eta</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">elbos</span><span class="p">),</span> <span class="p">(</span><span class="n">q_z</span><span class="p">,</span> <span class="n">q_theta</span><span class="p">,</span> <span class="n">q_eta</span><span class="p">)</span>
        
</pre></div>
</div>
</div>
</div>
</section>
<section id="test-your-implementation-on-a-toy-dataset">
<h3>Test your implementation on a toy dataset<a class="headerlink" href="#test-your-implementation-on-a-toy-dataset" title="Permalink to this heading">#</a></h3>
<p>To check your implementation is working properly, we will fit a mean-field variational posterior using data sampled from the true model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Constants</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>   <span class="c1"># num &quot;users&quot;</span>
<span class="n">M</span> <span class="o">=</span> <span class="mi">1000</span> <span class="c1"># num &quot;items&quot;</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">5</span>     <span class="c1"># number of latent factors</span>

<span class="c1"># Hyperparameters</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># sparse gamma prior with mean alpha/beta </span>
<span class="n">beta</span> <span class="o">=</span> <span class="mf">1.0</span>

<span class="c1"># Sample data from the model</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">305</span><span class="p">)</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">Gamma</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">sample_shape</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">K</span><span class="p">))</span>
<span class="n">eta</span> <span class="o">=</span> <span class="n">Gamma</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">sample_shape</span><span class="o">=</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">K</span><span class="p">))</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">Poisson</span><span class="p">(</span><span class="n">theta</span> <span class="o">@</span> <span class="n">eta</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># Plot the data matrix</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Greys&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;items&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;users&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Max data:  &quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;num zeros: &quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">data</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">elbos</span><span class="p">,</span> <span class="p">(</span><span class="n">q_z</span><span class="p">,</span> <span class="n">q_theta</span><span class="p">,</span> <span class="n">q_eta</span><span class="p">)</span> <span class="o">=</span> <span class="n">cavi</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">elbos</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Iteration&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;ELBO per entry&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">true_rates</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">@</span> <span class="n">eta</span><span class="o">.</span><span class="n">T</span>
<span class="n">inf_rates</span> <span class="o">=</span> <span class="n">q_theta</span><span class="o">.</span><span class="n">mean</span> <span class="o">@</span> <span class="n">q_eta</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">T</span>

<span class="c1"># Plot the data matrix</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">true_rates</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Greys&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;items&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;users&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;true rates&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">inf_rates</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Greys&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;items&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;users&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;inferred rates&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="problem-4-run-your-code-on-a-downsampled-lastfm-dataset">
<h2>Problem 4: Run your code on a downsampled LastFM dataset<a class="headerlink" href="#problem-4-run-your-code-on-a-downsampled-lastfm-dataset" title="Permalink to this heading">#</a></h2>
<p>Next, we will use data gathered from <span class="xref myst">Last.FM</span> users to fit a PMF model. We use a downsampled version of the <a class="reference external" href="http://ocelma.net/MusicRecommendationDataset/lastfm-360K.html">Last.FM-360K users</a> dataset. This dataset records how many times each user played an artist’s songs. We downsample the data to include only the 2000 most popular artists, as measured by how many users listened to the artist at least once, and the 1000 most prolific users, as measured by how many artists they have listened to.</p>
<p>In the code below , we use <code class="docutils literal notranslate"><span class="pre">lfm</span></code> to represent the data matrix <span class="math notranslate nohighlight">\(X\)</span> in the model. That is, <code class="docutils literal notranslate"><span class="pre">lfm[n,</span> <span class="pre">d]</span></code> denotes how many times the <code class="docutils literal notranslate"><span class="pre">n</span></code>-th user played a song by the <code class="docutils literal notranslate"><span class="pre">d</span></code>-th artist.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>wget<span class="w"> </span>-nc<span class="w"> </span>https://raw.githubusercontent.com/slinderman/stats305c/main/assignments/hw5/subsampled_last_fm.csv
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">lfm_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;subsampled_last_fm.csv&#39;</span><span class="p">)</span>
<span class="n">lfm</span> <span class="o">=</span> <span class="n">lfm_df</span><span class="o">.</span><span class="n">pivot_table</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="s1">&#39;UserID&#39;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="s1">&#39;ItemID&#39;</span><span class="p">,</span> <span class="n">aggfunc</span><span class="o">=</span><span class="nb">sum</span><span class="p">)</span>\
    <span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">lfm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">lfm</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lfm</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">lfm</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Greys&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;items&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;users&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Using the code below, run coordinate ascent variational inference on this dataset. Our implementation takes around 10-15 minutes to finish, and achieves a rescaled ELBO of around <span class="math notranslate nohighlight">\(-2\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">elbos</span><span class="p">,</span> <span class="p">(</span><span class="n">q_z</span><span class="p">,</span> <span class="n">q_theta</span><span class="p">,</span> <span class="n">q_eta</span><span class="p">)</span> <span class="o">=</span> <span class="n">cavi</span><span class="p">(</span><span class="n">lfm</span><span class="p">,</span> 
     <span class="n">num_factors</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> 
     <span class="n">num_iters</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> 
     <span class="n">alpha_theta</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span>
     <span class="n">beta_theta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
     <span class="n">alpha_eta</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span>
     <span class="n">beta_eta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">elbos</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<section id="investigate-genres">
<h3>Investigate “genres”<a class="headerlink" href="#investigate-genres" title="Permalink to this heading">#</a></h3>
<p>The columns of <span class="math notranslate nohighlight">\(\mathbf{H}\)</span> correspond to weights on artists. Intuitively, each of the <span class="math notranslate nohighlight">\(K\)</span> columns should put weight on subsets of artists that are often played together. We might think of these columns as reflecting different “genres” of music. The code below the top 10 artists for a few of these columns.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Find the 10 most used genres</span>
<span class="n">genre_loading</span> <span class="o">=</span> <span class="n">q_theta</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">genre_order</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">genre_loading</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Print the top 10 artists for each of the top 10 genres</span>
<span class="k">for</span> <span class="n">genre</span> <span class="ow">in</span> <span class="n">genre_order</span><span class="p">[:</span><span class="mi">10</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;genre &quot;</span><span class="p">,</span> <span class="n">genre</span><span class="p">)</span>
    <span class="n">artist_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">q_eta</span><span class="o">.</span><span class="n">mean</span><span class="p">[:,</span> <span class="n">genre</span><span class="p">],</span> 
                               <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">subset</span> <span class="o">=</span> <span class="n">lfm_df</span><span class="p">[</span><span class="n">lfm_df</span><span class="p">[</span><span class="s1">&#39;ItemID&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">artist_idx</span><span class="p">)]</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">subset</span><span class="p">[[</span><span class="s1">&#39;ItemID&#39;</span><span class="p">,</span> <span class="s1">&#39;Artist&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    
</pre></div>
</div>
</div>
</div>
</section>
<section id="problem-4a">
<h3>Problem 4a<a class="headerlink" href="#problem-4a" title="Permalink to this heading">#</a></h3>
<p>Inspect the data either using the csv file or the pandas dataframe and choose a user who has listened to artists you recognize. If you are not familiar with any of the artists, use the listener with UserID 349, who mostly listens to hip-hop artists. For the particular user <span class="math notranslate nohighlight">\(n\)</span> you choose, find the 10 artists who are predicted to have the most plays by sorting the vector of mean song counts predicted by the model, i.e. the <span class="math notranslate nohighlight">\(n^{\text{th}}\)</span> row of <span class="math notranslate nohighlight">\(\mathbb{E}_q [\boldsymbol{\Theta} \mathbf{H}^\top ]\)</span>. Are these artists you would expect the user would enjoy? Are there any artists that the user has not listened to?</p>
<p><em>Hint: Use <code class="docutils literal notranslate"><span class="pre">torch.argsort(...,</span> <span class="pre">descending=True)</span></code> to return the indices of the largest elements of a vector in descending order.</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">###</span>
<span class="c1"># Your code here.</span>
<span class="c1">##</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="problem-5-reflections">
<h2>Problem 5: Reflections<a class="headerlink" href="#problem-5-reflections" title="Permalink to this heading">#</a></h2>
<section id="problem-5a">
<h3>Problem 5a<a class="headerlink" href="#problem-5a" title="Permalink to this heading">#</a></h3>
<p>Discuss one advantage and one disadvantage of fitting a posterior using variational inference vs. sampling from the posterior using MCMC.</p>
<hr class="docutils" />
<p><em>Your answer here.</em></p>
</section>
<hr class="docutils" />
<section id="problem-5b">
<h3>Problem 5b<a class="headerlink" href="#problem-5b" title="Permalink to this heading">#</a></h3>
<p>First, explain why the assumption that <span class="math notranslate nohighlight">\(\mathbf{Z}, \mathbf{H}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{\Theta}\)</span> are independent in the posterior will never hold.</p>
<p>Next, recall that maximizing the ELBO is equivalent to minimizing the KL divergence between the approximate posterior and the true posterior. In general, how will the approximate posterior differ from the true posterior, given that the variational family does not include the true posterior?</p>
<hr class="docutils" />
<p><em>Your answer here.</em></p>
</section>
<hr class="docutils" />
<section id="problem-5c">
<h3>Problem 5c<a class="headerlink" href="#problem-5c" title="Permalink to this heading">#</a></h3>
<p>Suppose we are using this model to recommend new items to users. Describe one improvement that could be made to the model which you think would lead to better recommendations.</p>
<hr class="docutils" />
<p><em>Your answer here.</em></p>
</section>
</section>
<hr class="docutils" />
<section id="submission-instructions">
<h2>Submission Instructions<a class="headerlink" href="#submission-instructions" title="Permalink to this heading">#</a></h2>
<p><strong>Formatting:</strong> check that your code does not exceed 80 characters in line width. If you’re working in Colab, you can set <em>Tools → Settings → Editor → Vertical ruler column</em> to 80 to see when you’ve exceeded the limit.</p>
<p>Download your notebook in .ipynb format and use the following commands to convert it to PDF:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">jupyter</span> <span class="n">nbconvert</span> <span class="o">--</span><span class="n">to</span> <span class="n">pdf</span> <span class="n">hw5_yourname</span><span class="o">.</span><span class="n">ipynb</span>
</pre></div>
</div>
<p><strong>Dependencies:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">nbconvert</span></code>: If you’re using Anaconda for package management,</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">install</span> <span class="o">-</span><span class="n">c</span> <span class="n">anaconda</span> <span class="n">nbconvert</span>
</pre></div>
</div>
<p><strong>Upload</strong> your .pdf files to Gradescope.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./assignments/hw5"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="../hw4/hw4.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">HW4: Bayesian Mixture Models</p>
      </div>
    </a>
    <a class="right-next"
       href="../hw6/hw6.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">HW 6: Neural Networks and VAEs</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#background">Background</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#latent-variable-formulation">Latent variable formulation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-1-conditional-distributions-math">Problem 1: Conditional distributions [math]</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-1a-derive-the-conditional-for-mathbf-z-n-m">Problem 1a: Derive the conditional for <span class="math notranslate nohighlight">\(\mathbf{z}_{n, m}\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-1b-derive-the-conditional-for-theta-n-k">Problem 1b: Derive the conditional for <span class="math notranslate nohighlight">\(\theta_{n,k}\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-1c-derive-the-conditional-for-eta-m-k">Problem 1c: Derive the conditional for <span class="math notranslate nohighlight">\(\eta_{m, k}\)</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-2-coordinate-ascent-variational-inference-math">Problem 2: Coordinate ascent variational inference [math]</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-2a-derive-the-cavi-update-for-q-mathbf-z-n-m">Problem 2a: Derive the CAVI update for <span class="math notranslate nohighlight">\(q(\mathbf{z}_{n, m})\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-2b-derive-the-cavi-update-for-q-theta-n-k">Problem 2b: Derive the CAVI update for <span class="math notranslate nohighlight">\(q(\theta_{n, k})\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-2c-derive-the-cavi-update-for-q-eta-m-k">Problem 2c: Derive the CAVI update for <span class="math notranslate nohighlight">\(q(\eta_{m, k})\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-2d-find-the-expected-sufficient-statistics">Problem 2d: Find the expected sufficient statistics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-3-implement-coordinate-ascent-variational-inference-code">Problem 3: Implement Coordinate Ascent Variational Inference [code]</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-3a-implement-a-cavi-update-step">Problem 3a: Implement a CAVI update step</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-3b-elbo-calculation-math">Problem 3b: ELBO Calculation [math]</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-3c-implement-the-elbo-code">Problem 3c: Implement the ELBO [code]</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implement-cavi-loop-given">Implement CAVI loop [given]</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#test-your-implementation-on-a-toy-dataset">Test your implementation on a toy dataset</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-4-run-your-code-on-a-downsampled-lastfm-dataset">Problem 4: Run your code on a downsampled LastFM dataset</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#investigate-genres">Investigate “genres”</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-4a">Problem 4a</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-5-reflections">Problem 5: Reflections</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-5a">Problem 5a</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-5b">Problem 5b</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-5c">Problem 5c</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#submission-instructions">Submission Instructions</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Scott Linderman
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>