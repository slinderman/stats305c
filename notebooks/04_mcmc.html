

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Markov Chain Monte Carlo &#8212; Applied Statistics III</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/04_mcmc';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Coordinate Ascent Variational Inference for GMMs" href="09_cavi_gmm.html" />
    <link rel="prev" title="Hierarchical Gaussian Models" href="03_hier_gauss.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    <p class="title logo__title">Applied Statistics III</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Overview
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Assignments</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../assignments/hw0/hw0.html">HW0: PyTorch Primer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../assignments/hw1/hw1.html">HW1: Bayesian Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../assignments/hw2/hw2.html">HW2: Gibbs Sampling and Metropolis-Hastings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../assignments/hw3/hw3.html">HW3: Continuous Latent Variable Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../assignments/hw4/hw4.html">HW4: Bayesian Mixture Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../assignments/hw5/hw5.html">HW5: Poisson Matrix Factorization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../assignments/hw6/hw6.html">HW6: Neural Networks and VAEs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../assignments/hw7/hw7.html">HW7: Autoregressive HMMs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Notebooks</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01_bayes_normal.html">Bayesian Analysis of the Normal Distribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_mvn.html">The Multivariate Normal Distribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_hier_gauss.html">Hierarchical Gaussian Models</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Markov Chain Monte Carlo</a></li>
<li class="toctree-l1"><a class="reference internal" href="09_cavi_gmm.html">Coordinate Ascent Variational Inference for GMMs</a></li>
<li class="toctree-l1"><a class="reference internal" href="09_cavi_nix.html">CAVI in a Simple Gaussian Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="10_cavi_lda.html">Latent Dirichlet Allocation</a></li>
<li class="toctree-l1"><a class="reference internal" href="11_advi_nix.html">Gradient-based VI in a Simple Gaussian Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="12_nns_vaes.html">Neural Networks and VAEs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../lectures/99_references.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/slinderman/stats305c/blob/spring2023/notebooks/04_mcmc.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/04_mcmc.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Markov Chain Monte Carlo</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-inference-with-mcmc-in-the-hierarchical-gaussian-model">Bayesian inference with MCMC in the hierarchical Gaussian model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sample-synthetic-data">Sample synthetic data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gibbs-sampling">Gibbs Sampling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calculate-the-log-joint-probability">Calculate the log joint probability</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gibbs-update-for-theta-s">Gibbs update for <span class="math notranslate nohighlight">\(\theta_s\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gibbs-update-for-sigma-s-2">Gibbs update for <span class="math notranslate nohighlight">\(\sigma_s^2\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gibbs-update-for-mu">Gibbs update for <span class="math notranslate nohighlight">\(\mu\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gibbs-update-for-tau-2">Gibbs update for <span class="math notranslate nohighlight">\(\tau^2\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#put-it-all-together">Put it all together</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-summaries-of-the-mcmc-samples">Plot summaries of the MCMC samples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mcmc-diagnostics">MCMC Diagnostics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#recap">Recap</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="markov-chain-monte-carlo">
<h1>Markov Chain Monte Carlo<a class="headerlink" href="#markov-chain-monte-carlo" title="Permalink to this heading">#</a></h1>
<section id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Permalink to this heading">#</a></h2>
<p>We’ll use some utilities from Pyro, a probabilistic programming language that wraps PyTorch. Pyro requires PyTorch 1.11 so this <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span></code> command will take a little time.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>-q<span class="w"> </span>pyro-ppl<span class="w"> </span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="bayesian-inference-with-mcmc-in-the-hierarchical-gaussian-model">
<h2>Bayesian inference with MCMC in the hierarchical Gaussian model<a class="headerlink" href="#bayesian-inference-with-mcmc-in-the-hierarchical-gaussian-model" title="Permalink to this heading">#</a></h2>
<p>Let’s return to the “8 Schools” example from Lecture 3. To recap: we have test scores from <span class="math notranslate nohighlight">\(S\)</span> schools. Let <span class="math notranslate nohighlight">\(N_s\)</span> denote the number of students from school <span class="math notranslate nohighlight">\(s\)</span> and <span class="math notranslate nohighlight">\(x_{s,n} \in \mathbb{R}\)</span> denote the score of the <span class="math notranslate nohighlight">\(n\)</span>-th student from the <span class="math notranslate nohighlight">\(s\)</span>-th school.</p>
<p>We model the collection of scores using a <strong>hierarchical model</strong>. Unlike last time, now we will add a prior on the per-school variance as well.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
    \tau^2 &amp;\sim \chi^{-2}(\nu_0, \tau_0^2) \\
    \mu &amp;\sim \mathcal{N}(\mu_0, \tau^2 / \kappa_0) \\
    \theta_s &amp;\sim \mathcal{N}(\mu, \tau^2) &amp; \text{for } s&amp;=1,\ldots,S \\
    \sigma_s^2 &amp;\sim \chi^{-2}(\alpha_0, \sigma_0^2) &amp; \text{for } s&amp;=1,\ldots,S \\
    x_{s,n} &amp;\sim \mathcal{N}(\theta_s, \sigma_s^2) &amp; \text{for } n&amp;=1,\ldots,N_s \text{ and } s=1,\ldots,S
\end{align*}
\end{split}\]</div>
<p>Each school has its own mean <span class="math notranslate nohighlight">\(\theta_s\)</span> and variance <span class="math notranslate nohighlight">\(\sigma_s^2\)</span>. The means are linked via a hierarchical prior: they are conditionally independent given the global mean <span class="math notranslate nohighlight">\(\mu\)</span> and variance <span class="math notranslate nohighlight">\(\tau^2\)</span></p>
<p>We will use MCMC to draw approximate samples from the posterior distribution <span class="math notranslate nohighlight">\(p(\tau^2, \mu, \{\theta_s, \sigma_s^2\}_{s=1}^S \mid \{\{x_{s,n}\}_{n=1}^{N_s}\}_{s=1}^S, \eta)\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Setup</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.distributions</span> <span class="kn">import</span> <span class="n">Normal</span><span class="p">,</span> <span class="n">Gamma</span><span class="p">,</span> <span class="n">Categorical</span><span class="p">,</span> \
    <span class="n">TransformedDistribution</span>
<span class="kn">from</span> <span class="nn">torch.distributions.transforms</span> <span class="kn">import</span> <span class="n">PowerTransform</span>

<span class="kn">from</span> <span class="nn">pyro.ops.stats</span> <span class="kn">import</span> <span class="n">effective_sample_size</span><span class="p">,</span> <span class="n">autocorrelation</span>

<span class="kn">from</span> <span class="nn">fastprogress</span> <span class="kn">import</span> <span class="n">progress_bar</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.cm</span> <span class="kn">import</span> <span class="n">Blues</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s2">&quot;notebook&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ScaledInvChiSq</span><span class="p">(</span><span class="n">TransformedDistribution</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implementation of the scaled inverse \chi^2 distribution defined in class.</span>
<span class="sd">    We will implement it as a transformation of a gamma distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dof</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
        <span class="n">base</span> <span class="o">=</span> <span class="n">Gamma</span><span class="p">(</span><span class="n">dof</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dof</span> <span class="o">*</span> <span class="n">scale</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">transforms</span> <span class="o">=</span> <span class="p">[</span><span class="n">PowerTransform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span>
        <span class="n">TransformedDistribution</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base</span><span class="p">,</span> <span class="n">transforms</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dof</span> <span class="o">=</span> <span class="n">dof</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="sample-synthetic-data">
<h2>Sample synthetic data<a class="headerlink" href="#sample-synthetic-data" title="Permalink to this heading">#</a></h2>
<p>We will modify the data from the 8 shcools example of Gelman et al (2013). Specifically, we’ll sample 20 scores so that they have the same mean and the specified standard deviation.</p>
<p>Remember that <span class="math notranslate nohighlight">\(\bar{\sigma}_s = \sigma_s / \sqrt{N_s}\)</span> in our notation from Lecture 3.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Hyper parameters</span>
<span class="n">S</span> <span class="o">=</span> <span class="mi">8</span>                   <span class="c1"># number of schools</span>
<span class="n">N_s</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>  <span class="c1"># number of students per school</span>
<span class="n">mu_0</span> <span class="o">=</span> <span class="mf">0.0</span>              <span class="c1"># prior mean of the global effect</span>
<span class="n">kappa_0</span> <span class="o">=</span> <span class="mf">0.1</span>           <span class="c1"># prior concentration in the NIX prior</span>
<span class="n">nu_0</span> <span class="o">=</span> <span class="mf">0.1</span>              <span class="c1"># degrees of freedom for the prior on \tau^2</span>
<span class="n">tausq_0</span> <span class="o">=</span> <span class="mf">100.0</span>         <span class="c1"># prior mean of the variance \tau^2</span>
<span class="n">alpha_0</span> <span class="o">=</span> <span class="mf">0.1</span>           <span class="c1"># degrees of freedom for the prior on \sigma_s^2</span>
<span class="n">sigmasq_0</span> <span class="o">=</span> <span class="mf">10.0</span>        <span class="c1"># scale of the prior on \sigma_s^2</span>

<span class="c1"># Sample data</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">305</span><span class="p">)</span>
<span class="n">x_bars</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">28.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">18.</span><span class="p">,</span> <span class="mf">12.</span><span class="p">])</span>  
<span class="n">sigma_bars</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">15.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">,</span> <span class="mf">16.</span><span class="p">,</span> <span class="mf">11.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">11.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">,</span> <span class="mf">18.</span><span class="p">])</span>
<span class="n">xs</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">x_bars</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">N_s</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigma_bars</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">N_s</span><span class="p">,))</span>    

<span class="c1"># z-score the samples</span>
<span class="n">zs</span> <span class="o">=</span> <span class="p">(</span><span class="n">xs</span> <span class="o">-</span> <span class="n">xs</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="o">/</span> <span class="n">xs</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Rescale so they have the desired variance</span>
<span class="n">xs</span> <span class="o">=</span> <span class="n">x_bars</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">N_s</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigma_bars</span> <span class="o">*</span> <span class="n">zs</span>

<span class="c1"># Note: xs.shape == (N_s, S)</span>
<span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">xs</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">x_bars</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">xs</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">N_s</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigma_bars</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="gibbs-sampling">
<h2>Gibbs Sampling<a class="headerlink" href="#gibbs-sampling" title="Permalink to this heading">#</a></h2>
<p>We will use Gibbs sampling to draw approximate samples from the posterior distribution. The idea is to cycle between each latent variable and sample from its conditional distribution given the current settings of the remaining variables. In models like this one, the conditional distributions often have simple closed forms. We will derive and implement the updates one at a time.</p>
</section>
<section id="calculate-the-log-joint-probability">
<h2>Calculate the log joint probability<a class="headerlink" href="#calculate-the-log-joint-probability" title="Permalink to this heading">#</a></h2>
<p>First, we will write a function to compute the log joint probability.
This will be useful for tracking the Gibbs sampler’s progress over iterations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">log_probability</span><span class="p">(</span><span class="n">tausq</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">thetas</span><span class="p">,</span> <span class="n">sigmasqs</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span>
                    <span class="n">tausq_0</span><span class="p">,</span> <span class="n">nu_0</span><span class="p">,</span> <span class="n">mu_0</span><span class="p">,</span> <span class="n">kappa_0</span><span class="p">,</span> <span class="n">alpha_0</span><span class="p">,</span> <span class="n">sigmasq_0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the log joint probability of the model parameters and data given the </span>
<span class="sd">    hyperparameters of the model. </span>

<span class="sd">    Args:</span>

<span class="sd">    tausq:      a scalar \tau^2 value</span>
<span class="sd">    mu:         a scalar mu value</span>
<span class="sd">    thetas:     a shape (S,) tensor of \theta values</span>
<span class="sd">    sigmasqs:   a shape (S,) tensor of \sigma_s^2 values</span>
<span class="sd">    xs:         a shape (S, N_s) tensor of data points</span>
<span class="sd">    tausq_0:    scale of prior on \tau^2</span>
<span class="sd">    nu_0:       degrees of freedom of prior on \tau^2</span>
<span class="sd">    mu_0:       mean of prior on \mu</span>
<span class="sd">    kappa_0:    precision of prior on \mu</span>
<span class="sd">    alpha_0:    degrees of freedom of prior on \sigma_s^2</span>
<span class="sd">    sigmasq_0:  scale of prior on \sigma_s^2</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>

<span class="sd">    Log joint probability.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">lp</span> <span class="o">=</span> <span class="n">ScaledInvChiSq</span><span class="p">(</span><span class="n">nu_0</span><span class="p">,</span> <span class="n">tausq_0</span><span class="p">)</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">tausq</span><span class="p">)</span>
    <span class="n">lp</span> <span class="o">+=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">mu_0</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tausq</span> <span class="o">/</span> <span class="n">kappa_0</span><span class="p">))</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
    <span class="n">lp</span> <span class="o">+=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tausq</span><span class="p">))</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">thetas</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">lp</span> <span class="o">+=</span> <span class="n">ScaledInvChiSq</span><span class="p">(</span><span class="n">alpha_0</span><span class="p">,</span> <span class="n">sigmasq_0</span><span class="p">)</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">sigmasqs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">lp</span> <span class="o">+=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sigmasqs</span><span class="p">))</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">lp</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="gibbs-update-for-theta-s">
<h2>Gibbs update for <span class="math notranslate nohighlight">\(\theta_s\)</span><a class="headerlink" href="#gibbs-update-for-theta-s" title="Permalink to this heading">#</a></h2>
<p>We have</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
    p(\theta_s \mid \mu, \tau^2, \sigma_s^2, \mathbf{X}, \boldsymbol{\eta})
    &amp;\propto \mathcal{N}(\theta_s \mid \mu, \tau^2) \prod_{n=1}^{N_s} \mathcal{N}(x_{s,n} \mid \theta_s, \sigma_s^2) \\
    &amp;\propto \prod_{s=1}^S \mathcal{N}(\theta_s \mid \hat{\theta}_s, v_s)
\end{align*}
\end{split}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
    v_s &amp;= \left(\frac{N_s}{\sigma_s^2} + \frac{1}{\tau^2} \right)^{-1} &amp;
    \hat{\theta}_s &amp;= v_s \left(\sum_{n=1}^{N_s}\frac{x_{s,n}}{\sigma_s^2} + \frac{\mu}{\tau^2} \right)
\end{align*}
\]</div>
<p>I.e. the conditional means are precision-weighted averages of the prior and sample means.</p>
<p><strong>Note:</strong> all of the <span class="math notranslate nohighlight">\(\theta_s\)</span> parameters are conditionally independent given the remaining variables. That means we can sample them all in parallel using a <strong>blocked Gibbs update</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gibbs_sample_thetas</span><span class="p">(</span><span class="n">tausq</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigmasqs</span><span class="p">,</span> <span class="n">xs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sample the conditional distribution of \theta_s given all the other </span>
<span class="sd">    variables. Since the \theta_s parameters are conditionally independent given </span>
<span class="sd">    everything else, we can sample them in parallel as a blocked Gibbs step. </span>

<span class="sd">    Args:</span>

<span class="sd">    tausq:      a scalar \tau^2 value</span>
<span class="sd">    mu:         a scala mu value</span>
<span class="sd">    sigmasqs:   a shape (S,) tensor of \sigma_s^2 values</span>
<span class="sd">    xs:         a shape (S, N_s) tensor of data points</span>

<span class="sd">    Returns:</span>

<span class="sd">    A shape (S,) tensor of \theta_s values drawn from their complete conditional</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">N_s</span> <span class="o">=</span> <span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">v_theta</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">((</span><span class="n">N_s</span> <span class="o">/</span> <span class="n">sigmasqs</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">tausq</span><span class="p">))</span>
    <span class="n">theta_hat</span> <span class="o">=</span> <span class="n">v_theta</span> <span class="o">*</span> <span class="p">((</span><span class="n">xs</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigmasqs</span><span class="p">)</span> <span class="o">+</span> <span class="n">mu</span> <span class="o">/</span> <span class="n">tausq</span><span class="p">)</span>
    <span class="n">thetas</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">theta_hat</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v_theta</span><span class="p">))</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">thetas</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="gibbs-update-for-sigma-s-2">
<h2>Gibbs update for <span class="math notranslate nohighlight">\(\sigma_s^2\)</span><a class="headerlink" href="#gibbs-update-for-sigma-s-2" title="Permalink to this heading">#</a></h2>
<p>The conditional distribution of <span class="math notranslate nohighlight">\(\sigma_s^2\)</span> given all the other variables is,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
p(\sigma_s^2 \mid \theta_s, \{x_{s,n}\}_{n=1}^{N_s}, \alpha_0, \sigma_0^2) &amp;\propto 
\chi^{-2}(\sigma_s^2 \mid \alpha_0, \sigma_0^2) \prod_{n=1}^{N_s} \mathcal{N}(x_{s,n} \mid \theta_s, \sigma_s^2) \\
&amp;\propto \chi^{-2}(\sigma_s^2 \mid \alpha_N, \sigma_N^2) 
\end{align*}
\end{split}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\alpha_N &amp;= \alpha_0 + N_s \\
\sigma_N^2 &amp;= \frac{1}{\alpha_N} \left(\alpha_0 \sigma_0^2 + \sum_{n=1}^{N_s} (x_{s,n} - \theta_s)^2 \right) 
\end{align*}
\end{split}\]</div>
<p><strong>Note:</strong> Recall Lecture 1 on a normal model with unknown variance. Same thing here.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gibbs_sample_sigmasq</span><span class="p">(</span><span class="n">alpha_0</span><span class="p">,</span> <span class="n">sigmasq_0</span><span class="p">,</span> <span class="n">thetas</span><span class="p">,</span> <span class="n">xs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sample the conditional distribution of \sigma_s^2 given all the other </span>
<span class="sd">    variables. Since the \sigma_s^2 parameters are conditionally independent </span>
<span class="sd">    given everything else, we can sample them in parallel as a blocked Gibbs </span>
<span class="sd">    step. </span>

<span class="sd">    Args:</span>

<span class="sd">    alpha_0:    degrees of freedom of prior on \sigma_s^2</span>
<span class="sd">    sigmasq_0:  scale of prior on \sigma_s^2</span>
<span class="sd">    thetas:     a shape (S,) tensor of \theta_s values</span>
<span class="sd">    xs:         a shape (S, N_s) tensor of data points</span>

<span class="sd">    Returns:</span>

<span class="sd">    A shape (S,) tensor of \sigma_s^2 values drawn from their complete </span>
<span class="sd">    conditional distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">N_s</span> <span class="o">=</span> <span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">alpha_N</span> <span class="o">=</span> <span class="n">alpha_0</span> <span class="o">+</span> <span class="n">N_s</span>
    <span class="n">sigmasq_N</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">alpha_N</span> <span class="o">*</span> <span class="p">(</span><span class="n">alpha_0</span> <span class="o">*</span> <span class="n">sigmasq_0</span> 
                               <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">xs</span> <span class="o">-</span> <span class="n">thetas</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">ScaledInvChiSq</span><span class="p">(</span><span class="n">alpha_N</span><span class="p">,</span> <span class="n">sigmasq_N</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="gibbs-update-for-mu">
<h2>Gibbs update for <span class="math notranslate nohighlight">\(\mu\)</span><a class="headerlink" href="#gibbs-update-for-mu" title="Permalink to this heading">#</a></h2>
<p>The conditional distribution of <span class="math notranslate nohighlight">\(\mu\)</span> given everything else is,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
p(\mu \mid \{\theta_s\}_{s=1}^S, \tau^2, \mu_0, \kappa_0) 
&amp;\propto \mathcal{N}(\mu \mid \mu_0, \tau^2 / \kappa_0) \prod_{s=1}^S \mathcal{N}(\theta_s \mid \mu, \tau^2) \\
&amp;\propto \mathcal{N}(\mu \mid \hat{\mu}, v_\mu) 
\end{align*}
\end{split}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
v_\mu &amp;= \frac{1}{\frac{\kappa_0}{\tau^2} + \frac{S}{\tau^2}} = \frac{\tau^2}{\kappa_0 + S} \\
\hat{\mu} &amp;= v_\mu \left( \frac{\mu_0 \kappa_0}{\tau^2} + \sum_{s=1}^S \frac{\theta_s}{\tau^2} \right) = \frac{\mu_0 \kappa_0 + \sum_{s=1}^S \theta_s }{\kappa_0 + S}
\end{align*}
\end{split}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gibbs_sample_mu</span><span class="p">(</span><span class="n">mu_0</span><span class="p">,</span> <span class="n">kappa_0</span><span class="p">,</span> <span class="n">tausq</span><span class="p">,</span> <span class="n">thetas</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sample the conditional distribution of \mu given all the other </span>
<span class="sd">    variables. </span>

<span class="sd">    Args:</span>

<span class="sd">    mu_0:       mean of prior on \mu</span>
<span class="sd">    kappa_0:    precision of prior on \mu</span>
<span class="sd">    tausq:      sample of the global variance, \tau^2</span>
<span class="sd">    thetas:     a shape (S,) tensor of \theta_s values</span>

<span class="sd">    Returns:</span>

<span class="sd">    Scalar sample of \mu from its complete conditional distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">S</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">thetas</span><span class="p">)</span>
    <span class="n">v_mu</span> <span class="o">=</span> <span class="n">tausq</span> <span class="o">/</span> <span class="p">(</span><span class="n">kappa_0</span> <span class="o">+</span> <span class="n">S</span><span class="p">)</span>
    <span class="n">mu_hat</span> <span class="o">=</span> <span class="p">(</span><span class="n">mu_0</span> <span class="o">*</span> <span class="n">kappa_0</span> <span class="o">+</span> <span class="n">thetas</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">kappa_0</span> <span class="o">+</span> <span class="n">S</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Normal</span><span class="p">(</span><span class="n">mu_hat</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v_mu</span><span class="p">))</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="gibbs-update-for-tau-2">
<h2>Gibbs update for <span class="math notranslate nohighlight">\(\tau^2\)</span><a class="headerlink" href="#gibbs-update-for-tau-2" title="Permalink to this heading">#</a></h2>
<p>The conditional distribution of <span class="math notranslate nohighlight">\(\tau^2\)</span> given everything else is,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
p(\tau^2 \mid \mu, \{\theta_s\}_{s=1}^S, \nu_0, \tau_0^2) 
&amp;\propto \chi^{-2}(\tau^2 \mid \nu_0, \tau_0^2) \mathcal{N}(\mu \mid \mu_0, \tau^2 / \kappa_0) \prod_{s=1}^S \mathcal{N}(\theta_s \mid \mu, \tau^2) \\
&amp;\propto \chi^{-2}(\tau^2 \mid \nu_N, \tau_N^2) 
\end{align*}
\end{split}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\nu_N &amp;= \nu_0 + S + 1 \\
\tau_N^2 &amp;= \frac{1}{\nu_N} \left( \nu_0 \tau_0^2 + \kappa_0 (\mu - \mu_0)^2 + \sum_{s=1}^S (\theta_s - \mu)^2 \right)
\end{align*}
\end{split}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gibbs_sample_tausq</span><span class="p">(</span><span class="n">nu_0</span><span class="p">,</span> <span class="n">tausq_0</span><span class="p">,</span> <span class="n">mu_0</span><span class="p">,</span> <span class="n">kappa_0</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">thetas</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sample the conditional distribution of \mu given all the other </span>
<span class="sd">    variables. </span>

<span class="sd">    Args:</span>

<span class="sd">    nu_0:       degrees of freedom of prior on \tau^2</span>
<span class="sd">    tausq_0:    scale of prior on \tau^2</span>
<span class="sd">    mu_0:       mean of prior on \mu</span>
<span class="sd">    kappa_0:    precision of prior on \mu</span>
<span class="sd">    mu:         sample of the global mean, \mu</span>
<span class="sd">    thetas:     a shape (S,) tensor of \theta_s values</span>

<span class="sd">    Returns:</span>

<span class="sd">    Scalar sample of \tau^2 from its complete conditional distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">S</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">thetas</span><span class="p">)</span>
    <span class="n">nu_N</span> <span class="o">=</span> <span class="n">nu_0</span> <span class="o">+</span> <span class="n">S</span> <span class="o">+</span> <span class="mi">1</span> 
    <span class="n">tausq_N</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">nu_N</span> <span class="o">*</span> <span class="p">(</span><span class="n">nu_0</span> <span class="o">*</span> <span class="n">tausq_0</span> <span class="o">+</span> <span class="n">kappa_0</span> <span class="o">*</span> <span class="p">(</span><span class="n">mu</span> <span class="o">-</span> <span class="n">mu_0</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> 
                        <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">thetas</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">ScaledInvChiSq</span><span class="p">(</span><span class="n">nu_N</span><span class="p">,</span> <span class="n">tausq_N</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="put-it-all-together">
<h2>Put it all together<a class="headerlink" href="#put-it-all-together" title="Permalink to this heading">#</a></h2>
<p>That’s all the updates! All that is left is a simple function to cycle through these updates one at a time. After each iteration, we will compute and save the log joint probability.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gibbs</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">tausq_0</span><span class="p">,</span> <span class="n">nu_0</span><span class="p">,</span> <span class="n">mu_0</span><span class="p">,</span> <span class="n">kappa_0</span><span class="p">,</span> <span class="n">alpha_0</span><span class="p">,</span> <span class="n">sigmasq_0</span><span class="p">,</span> <span class="n">N_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Run the Gibbs sampler.</span>

<span class="sd">    Args:</span>

<span class="sd">    xs:         a shape (S, N_s) tensor of data points</span>
<span class="sd">    tausq_0:    scale of prior on \tau^2</span>
<span class="sd">    nu_0:       degrees of freedom of prior on \tau^2</span>
<span class="sd">    mu_0:       mean of prior on \mu</span>
<span class="sd">    kappa_0:    precision of prior on \mu</span>
<span class="sd">    alpha_0:    degrees of freedom of prior on \sigma_s^2</span>
<span class="sd">    sigmasq_0:  scale of prior on \sigma_s^2</span>
<span class="sd">    N_samples:  number of Gibbs iterations to run</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>

<span class="sd">    Dictionary with samples of the parameters tausq, mu, thetas, sigmasqs, and </span>
<span class="sd">    the log joint probability at each iteration.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">N_s</span><span class="p">,</span> <span class="n">S</span> <span class="o">=</span> <span class="n">xs</span><span class="o">.</span><span class="n">shape</span>

    <span class="c1"># Initialize the Gibbs sampler with a draw from the prior</span>
    <span class="n">tausq</span> <span class="o">=</span> <span class="n">ScaledInvChiSq</span><span class="p">(</span><span class="n">nu_0</span><span class="p">,</span> <span class="n">tausq_0</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">mu_0</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tausq</span> <span class="o">/</span> <span class="n">kappa_0</span><span class="p">))</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
    <span class="n">thetas</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tausq</span><span class="p">))</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">S</span><span class="p">,))</span>
    <span class="n">sigmasqs</span> <span class="o">=</span> <span class="n">ScaledInvChiSq</span><span class="p">(</span><span class="n">alpha_0</span><span class="p">,</span> <span class="n">sigmasq_0</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">S</span><span class="p">,))</span>

    <span class="c1"># Compute the initial log probability</span>
    <span class="n">lp</span> <span class="o">=</span> <span class="n">log_probability</span><span class="p">(</span><span class="n">tausq</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">thetas</span><span class="p">,</span> <span class="n">sigmasqs</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span>
                         <span class="n">tausq_0</span><span class="p">,</span> <span class="n">nu_0</span><span class="p">,</span> <span class="n">mu_0</span><span class="p">,</span> <span class="n">kappa_0</span><span class="p">,</span> <span class="n">alpha_0</span><span class="p">,</span> <span class="n">sigmasq_0</span><span class="p">)</span>
    
    <span class="c1"># Initialize the output</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="p">[(</span><span class="n">tausq</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">thetas</span><span class="p">,</span> <span class="n">sigmasqs</span><span class="p">,</span> <span class="n">lp</span><span class="p">)]</span>

    <span class="c1"># Run the Gibbs sampler</span>
    <span class="k">for</span> <span class="n">itr</span> <span class="ow">in</span> <span class="n">progress_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">N_samples</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)):</span>
        <span class="c1"># Cycle through each update </span>
        <span class="n">tausq</span> <span class="o">=</span> <span class="n">gibbs_sample_tausq</span><span class="p">(</span><span class="n">nu_0</span><span class="p">,</span> <span class="n">tausq_0</span><span class="p">,</span> <span class="n">mu_0</span><span class="p">,</span> <span class="n">kappa_0</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">thetas</span><span class="p">)</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="n">gibbs_sample_mu</span><span class="p">(</span><span class="n">mu_0</span><span class="p">,</span> <span class="n">kappa_0</span><span class="p">,</span> <span class="n">tausq</span><span class="p">,</span> <span class="n">thetas</span><span class="p">)</span>
        <span class="n">thetas</span> <span class="o">=</span> <span class="n">gibbs_sample_thetas</span><span class="p">(</span><span class="n">tausq</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigmasqs</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>
        <span class="n">sigmasqs</span> <span class="o">=</span> <span class="n">gibbs_sample_sigmasq</span><span class="p">(</span><span class="n">alpha_0</span><span class="p">,</span> <span class="n">sigmasq_0</span><span class="p">,</span> <span class="n">thetas</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>

        <span class="c1"># Compute the log probability</span>
        <span class="n">lp</span> <span class="o">=</span> <span class="n">log_probability</span><span class="p">(</span><span class="n">tausq</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">thetas</span><span class="p">,</span> <span class="n">sigmasqs</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span>
                             <span class="n">tausq_0</span><span class="p">,</span> <span class="n">nu_0</span><span class="p">,</span> <span class="n">mu_0</span><span class="p">,</span> <span class="n">kappa_0</span><span class="p">,</span> <span class="n">alpha_0</span><span class="p">,</span> <span class="n">sigmasq_0</span><span class="p">)</span>
        
        <span class="c1"># Update the sample list</span>
        <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">tausq</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">thetas</span><span class="p">,</span> <span class="n">sigmasqs</span><span class="p">,</span> <span class="n">lp</span><span class="p">))</span>

    <span class="c1"># Combine the output into a dictionary with a cool python zip trick</span>
    <span class="n">samples_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;tausq&quot;</span><span class="p">,</span> <span class="s2">&quot;mu&quot;</span><span class="p">,</span> <span class="s2">&quot;thetas&quot;</span><span class="p">,</span> <span class="s2">&quot;sigmasqs&quot;</span><span class="p">,</span> <span class="s2">&quot;lps&quot;</span><span class="p">]</span>
    <span class="n">values</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">samples</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
        <span class="n">samples_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">samples_dict</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N_samples</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">gibbs</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">tausq_0</span><span class="p">,</span> <span class="n">nu_0</span><span class="p">,</span> <span class="n">mu_0</span><span class="p">,</span> <span class="n">kappa_0</span><span class="p">,</span> <span class="n">alpha_0</span><span class="p">,</span> <span class="n">sigmasq_0</span><span class="p">,</span> <span class="n">N_samples</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        </style>
      <progress value='9999' class='' max='9999' style='width:300px; height:20px; vertical-align: middle;'></progress>
      100.00% [9999/9999 00:12<00:00]
    </div>
    </div></div>
</div>
</section>
<section id="plot-summaries-of-the-mcmc-samples">
<h2>Plot summaries of the MCMC samples<a class="headerlink" href="#plot-summaries-of-the-mcmc-samples" title="Permalink to this heading">#</a></h2>
<p>First, let’s look at a trace of the log joint probability over iterations</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N_samples</span><span class="p">),</span> <span class="n">samples</span><span class="p">[</span><span class="s2">&quot;lps&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Iteration&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Log Joint Probability&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="c1"># plt.savefig(&quot;lps1.pdf&quot;)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/187a08b858df33284c8cc305e08628835f002ca77c3338e9d784771f038c3066.png" src="../_images/187a08b858df33284c8cc305e08628835f002ca77c3338e9d784771f038c3066.png" />
</div>
</div>
<p>We see that the first few iterations are simply <strong>burning in</strong> the chain. We will discard these iterations in our subsequent analyses.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">burnin</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">burnin</span><span class="p">,</span> <span class="n">N_samples</span><span class="p">),</span> <span class="n">samples</span><span class="p">[</span><span class="s2">&quot;lps&quot;</span><span class="p">][</span><span class="n">burnin</span><span class="p">:])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Iteration&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Log Joint Probability&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="c1"># plt.savefig(&quot;lps2.pdf&quot;)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/3f601e6c0379cf2e27f08711a2e201718451ae94003d5cfd24ba92140b68584e.png" src="../_images/3f601e6c0379cf2e27f08711a2e201718451ae94003d5cfd24ba92140b68584e.png" />
</div>
</div>
<p>The trace from iteration 100 onward looks much more stable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">burnin</span><span class="p">,</span> <span class="n">N_samples</span><span class="p">),</span> 
            <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&quot;tausq&quot;</span><span class="p">][</span><span class="n">burnin</span><span class="p">:]))</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Iteration&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\tau$ samples&quot;</span><span class="p">)</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&quot;tausq&quot;</span><span class="p">][</span><span class="n">burnin</span><span class="p">:]),</span> <span class="mi">50</span><span class="p">,</span> 
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\tau$&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$p(\tau \mid \mathbf</span><span class="si">{X}</span><span class="s2">, \mathbf{\eta})$&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="c1"># plt.savefig(&quot;tau_samples.pdf&quot;)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/5234ca6dad927235c0b0181eac9cd5cf126b8b3ab381ba9334c66be2ae661efd.png" src="../_images/5234ca6dad927235c0b0181eac9cd5cf126b8b3ab381ba9334c66be2ae661efd.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">burnin</span><span class="p">,</span> <span class="n">N_samples</span><span class="p">),</span> <span class="n">samples</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">][</span><span class="n">burnin</span><span class="p">:])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Iteration&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\mu$ samples&quot;</span><span class="p">)</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">][</span><span class="n">burnin</span><span class="p">:],</span> <span class="mi">50</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\mu$&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$p(\mu \mid \mathbf</span><span class="si">{X}</span><span class="s2">, \mathbf{\eta})$&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="c1"># plt.savefig(&quot;mu_samples.pdf&quot;)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/76dcc723b93be6db28d03065a13a058afd582a3aa7ba6c08fba3636d246f3d5d.png" src="../_images/76dcc723b93be6db28d03065a13a058afd582a3aa7ba6c08fba3636d246f3d5d.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">S</span><span class="p">):</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">burnin</span><span class="p">,</span> <span class="n">N_samples</span><span class="p">),</span> <span class="n">samples</span><span class="p">[</span><span class="s2">&quot;thetas&quot;</span><span class="p">][</span><span class="n">burnin</span><span class="p">:,</span> <span class="n">s</span><span class="p">])</span>
    
    <span class="k">if</span> <span class="n">s</span> <span class="o">==</span> <span class="n">S</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span> <span class="n">axs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Iteration&quot;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\theta_</span><span class="si">{}</span><span class="s2">$&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">s</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;School </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">s</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">N_samples</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">30</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="c1"># plt.savefig(&quot;theta_samples1.pdf&quot;)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/9ee03fb399b9efe7f0b6050e03a008c5202af789e86af671afba74fd17d8385f.png" src="../_images/9ee03fb399b9efe7f0b6050e03a008c5202af789e86af671afba74fd17d8385f.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bins</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">30</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">S</span><span class="p">):</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&quot;thetas&quot;</span><span class="p">][:,</span> <span class="n">s</span><span class="p">],</span> <span class="n">bins</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> 
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># axs[s].plot([x_bars[s], x_bars[s]], [0, 0.05], &#39;-r&#39;)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xs</span><span class="p">[:,</span> <span class="n">s</span><span class="p">])</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">],</span> <span class="s1">&#39;-r&#39;</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">s</span> <span class="o">==</span> <span class="n">S</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span> <span class="n">axs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\theta_s$&quot;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$p(\theta_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">s</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> \
                      <span class="o">+</span> <span class="sa">r</span><span class="s2">&quot; \mid \mathbf</span><span class="si">{X}</span><span class="s2">, \mathbf{\eta})$&quot;</span><span class="p">,</span>
                      <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;School </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">s</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="c1"># plt.savefig(&quot;theta_samples2.pdf&quot;)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7cece2d2ae6c76570ed16321ea6f7ef1c71f6047221d15479cb2b4bde927a554.png" src="../_images/7cece2d2ae6c76570ed16321ea6f7ef1c71f6047221d15479cb2b4bde927a554.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">S</span><span class="p">):</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">burnin</span><span class="p">,</span> <span class="n">N_samples</span><span class="p">),</span> 
                <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&quot;sigmasqs&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">N_s</span><span class="p">)[</span><span class="n">burnin</span><span class="p">:,</span> <span class="n">s</span><span class="p">])</span>
    
    <span class="k">if</span> <span class="n">s</span> <span class="o">==</span> <span class="n">S</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span> <span class="n">axs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Iteration&quot;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\bar{{\sigma}}_</span><span class="si">{}</span><span class="s2">$&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">s</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;School </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">s</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">N_samples</span><span class="p">)</span>
    <span class="c1"># axs[s].set_ylim(-30, 30)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="c1"># plt.savefig(&quot;sigma_samples1.pdf&quot;)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/1b08dca951186070f117a70ce56e22d87601932a2c905db27215dffdd615f671.png" src="../_images/1b08dca951186070f117a70ce56e22d87601932a2c905db27215dffdd615f671.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bins</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">S</span><span class="p">):</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&quot;sigmasqs&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">N_s</span><span class="p">)[:,</span> <span class="n">s</span><span class="p">],</span> <span class="n">bins</span><span class="p">,</span> 
                <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># axs[s].plot([x_bars[s], x_bars[s]], [0, 0.05], &#39;-r&#39;)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sigma_bars</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">],</span> <span class="s1">&#39;-r&#39;</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">s</span> <span class="o">==</span> <span class="n">S</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span> <span class="n">axs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\bar{\sigma}_s$&quot;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$p(\bar{\sigma}_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">s</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> \
                      <span class="sa">r</span><span class="s2">&quot; \mid \mathbf</span><span class="si">{X}</span><span class="s2">, \mathbf{\eta})$&quot;</span><span class="p">,</span>
                      <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;School </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">s</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="c1"># plt.savefig(&quot;sigma_samples2.pdf&quot;)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/2b7411ade1a8447a30de782500b4e34691456bc294cdde50888f20b03cff3cd3.png" src="../_images/2b7411ade1a8447a30de782500b4e34691456bc294cdde50888f20b03cff3cd3.png" />
</div>
</div>
</section>
<section id="mcmc-diagnostics">
<h2>MCMC Diagnostics<a class="headerlink" href="#mcmc-diagnostics" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">acf_tausq</span> <span class="o">=</span> <span class="n">autocorrelation</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&quot;tausq&quot;</span><span class="p">][</span><span class="n">burnin</span><span class="p">:]))</span>
<span class="n">acf_mu</span> <span class="o">=</span> <span class="n">autocorrelation</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">][</span><span class="n">burnin</span><span class="p">:])</span>
<span class="n">acf_theta1</span> <span class="o">=</span> <span class="n">autocorrelation</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&quot;thetas&quot;</span><span class="p">][</span><span class="n">burnin</span><span class="p">:,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">acf_sigma1</span> <span class="o">=</span> <span class="n">autocorrelation</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&quot;sigmasqs&quot;</span><span class="p">])[</span><span class="n">burnin</span><span class="p">:,</span> <span class="mi">0</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">acf_tausq</span><span class="p">[:</span><span class="mi">250</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;$\tau$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">acf_mu</span><span class="p">[:</span><span class="mi">250</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;$\mu$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">acf_theta1</span><span class="p">[:</span><span class="mi">250</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;$\theta_1$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">acf_sigma1</span><span class="p">[:</span><span class="mi">250</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;$\sigma_1$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;lag&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;autocorrelation&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="c1"># plt.savefig(&quot;acf.pdf&quot;)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/581ceb8b706bd22d349c4b88aecb27ff6ba60b173fb0424d6c88c7584c59016d.png" src="../_images/581ceb8b706bd22d349c4b88aecb27ff6ba60b173fb0424d6c88c7584c59016d.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Effective sample sizes:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;tausq:    &quot;</span><span class="p">,</span> <span class="n">effective_sample_size</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&quot;tausq&quot;</span><span class="p">][</span><span class="kc">None</span><span class="p">,</span> <span class="n">burnin</span><span class="p">:]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mu:       &quot;</span><span class="p">,</span> <span class="n">effective_sample_size</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">][</span><span class="kc">None</span><span class="p">,</span> <span class="n">burnin</span><span class="p">:]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;theta1:   &quot;</span><span class="p">,</span> <span class="n">effective_sample_size</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&quot;thetas&quot;</span><span class="p">][</span><span class="kc">None</span><span class="p">,</span> <span class="n">burnin</span><span class="p">:,</span> <span class="mi">0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sigamsq1: &quot;</span><span class="p">,</span> <span class="n">effective_sample_size</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&quot;sigmasqs&quot;</span><span class="p">][</span><span class="kc">None</span><span class="p">,</span> <span class="n">burnin</span><span class="p">:,</span> <span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Effective sample sizes:
tausq:     tensor(1563.3730)
mu:        tensor(625.2454)
theta1:    tensor(1027.9814)
sigamsq1:  tensor(8996.0498)
</pre></div>
</div>
</div>
</div>
</section>
<section id="recap">
<h2>Recap<a class="headerlink" href="#recap" title="Permalink to this heading">#</a></h2>
<p>This notebook implemented a Gibbs sampler for the hierarchical Gaussian model from Lecture 3. We showed:</p>
<ul class="simple">
<li><p>How to derive the <strong>complte conditional</strong> distributions for each variable and sample from them.</p></li>
<li><p>A <strong>blocked Gibbs update</strong> for the per-school means and variances, since those parameters are conditionally independent given the rest.</p></li>
<li><p>Monitoring the algorithm’s performance by plotting the log joint probability over iterations.</p></li>
<li><p>Visualizing of the <strong>posterior marginal probabilities</strong> for each variable by simply taking a histogram of samples (after discarding a few burnin samples).</p></li>
<li><p>MCMC diagnostics like the <strong>autocorrelation function</strong> and the <strong>effective sample size.</strong></p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="03_hier_gauss.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Hierarchical Gaussian Models</p>
      </div>
    </a>
    <a class="right-next"
       href="09_cavi_gmm.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Coordinate Ascent Variational Inference for GMMs</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-inference-with-mcmc-in-the-hierarchical-gaussian-model">Bayesian inference with MCMC in the hierarchical Gaussian model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sample-synthetic-data">Sample synthetic data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gibbs-sampling">Gibbs Sampling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calculate-the-log-joint-probability">Calculate the log joint probability</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gibbs-update-for-theta-s">Gibbs update for <span class="math notranslate nohighlight">\(\theta_s\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gibbs-update-for-sigma-s-2">Gibbs update for <span class="math notranslate nohighlight">\(\sigma_s^2\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gibbs-update-for-mu">Gibbs update for <span class="math notranslate nohighlight">\(\mu\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gibbs-update-for-tau-2">Gibbs update for <span class="math notranslate nohighlight">\(\tau^2\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#put-it-all-together">Put it all together</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-summaries-of-the-mcmc-samples">Plot summaries of the MCMC samples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mcmc-diagnostics">MCMC Diagnostics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#recap">Recap</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Scott Linderman
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>